"""Database Consolidation - Phase 4: Documentation and Cleanup.

This migration:
1. Documents all 20 tables in system_schema_metadata
2. Recreates legitimate JOIN views with new table names
3. Drops all 13 backward-compatibility views
4. Documents the 2 legitimate views

Author: architect
Date: 2025-10-25
Related: DATABASE_CONSOLIDATION_PLAN.md
"""

import sqlite3
from pathlib import Path
from datetime import datetime


# Table documentation metadata
TABLE_DOCS = [
    # ROADMAP DOMAIN
    {
        "entity_name": "roadmap_priority",
        "description": "Strategic priorities and user stories from ROADMAP.md",
        "purpose": "Primary source of truth for project priorities. Project_manager ONLY has write access.",
        "usage_notes": "Use RoadmapDatabase class for all access. Direct file access to ROADMAP.md is FORBIDDEN.",
        "related_tables": '["specs_specification", "roadmap_audit", "roadmap_notification"]',
    },
    {
        "entity_name": "roadmap_audit",
        "description": "Audit trail for all changes to roadmap priorities",
        "purpose": "Track who changed what and when for accountability",
        "usage_notes": "Automatically populated by RoadmapDatabase. Read-only for analysis.",
        "related_tables": '["roadmap_priority"]',
    },
    {
        "entity_name": "roadmap_metadata",
        "description": "Metadata for ROADMAP.md (header/footer content)",
        "purpose": "Store non-priority content from ROADMAP.md",
        "usage_notes": "Key-value store for header, footer, etc.",
        "related_tables": '["roadmap_priority"]',
    },
    {
        "entity_name": "roadmap_notification",
        "description": "Status update notifications for roadmap changes",
        "purpose": "Track notifications sent about roadmap updates",
        "usage_notes": "Used by notification system to avoid duplicate alerts",
        "related_tables": '["roadmap_priority"]',
    },
    # SPECS DOMAIN
    {
        "entity_name": "specs_specification",
        "description": "Technical specifications for implementation",
        "purpose": "Store technical design documents (hierarchical or markdown format)",
        "usage_notes": "Hierarchical specs stored in content field as JSON. Markdown specs as plain text.",
        "content_type": "JSON for hierarchical, TEXT for markdown",
        "related_tables": '["roadmap_priority", "specs_task", "review_code_review"]',
    },
    {
        "entity_name": "specs_task",
        "description": "Implementation tasks broken down from specs",
        "purpose": "Parallelizable work units for code_developer to claim and execute",
        "usage_notes": "Managed by ImplementationTaskManager. Sequential ordering enforced via priority_order.",
        "related_tables": '["specs_specification", "specs_task_dependency", "review_commit"]',
    },
    {
        "entity_name": "specs_task_dependency",
        "description": "Dependencies between task groups for ordered execution",
        "purpose": "Prevent parallel execution when tasks have hard dependencies",
        "usage_notes": "dependency_type: 'hard' blocks execution, 'soft' is advisory only",
        "related_tables": '["specs_task"]',
    },
    # REVIEW DOMAIN
    {
        "entity_name": "review_code_review",
        "description": "Code review reports from code-reviewer agent",
        "purpose": "Store automated code review findings and quality metrics",
        "usage_notes": "Generated by code-reviewer agent. Notifies architect of issues.",
        "related_tables": '["specs_specification", "roadmap_priority", "review_commit"]',
    },
    {
        "entity_name": "review_commit",
        "description": "Git commits associated with implementation tasks",
        "purpose": "Track which commits implement which tasks for traceability",
        "usage_notes": "Populated by code_developer when completing tasks",
        "related_tables": '["specs_task", "review_code_review"]',
    },
    # ORCHESTRATOR DOMAIN
    {
        "entity_name": "orchestrator_state",
        "description": "Persistent state for orchestrator daemon",
        "purpose": "Store orchestrator configuration and runtime state",
        "usage_notes": "Key-value store. DO NOT modify directly - use orchestrator APIs.",
        "related_tables": '["orchestrator_task", "orchestrator_bug"]',
    },
    {
        "entity_name": "orchestrator_task",
        "description": "Tasks managed by orchestrator for parallel execution",
        "purpose": "Track work assigned to parallel agents by orchestrator",
        "usage_notes": "Used by orchestrator for coordination. Status tracking.",
        "related_tables": '["orchestrator_state", "specs_task"]',
    },
    {
        "entity_name": "orchestrator_bug",
        "description": "Bugs discovered during autonomous development",
        "purpose": "Track issues found by code-reviewer or other agents",
        "usage_notes": "Automatically populated. Project_manager monitors for resolution.",
        "related_tables": '["orchestrator_state", "review_code_review"]',
    },
    # AGENT DOMAIN
    {
        "entity_name": "agent_lifecycle",
        "description": "Agent registration and lifecycle tracking",
        "purpose": "Enforce singleton agent instances (CFR-000)",
        "usage_notes": "Managed by AgentRegistry. DO NOT modify directly.",
        "related_tables": "[]",
    },
    {
        "entity_name": "agent_message",
        "description": "Inter-agent messages for coordination",
        "purpose": "Communication channel between autonomous agents",
        "usage_notes": "Message queue for asynchronous agent communication",
        "related_tables": '["agent_lifecycle"]',
    },
    # NOTIFICATION DOMAIN
    {
        "entity_name": "notification_user",
        "description": "User-facing notifications from all agents",
        "purpose": "Desktop notifications for important events (CFR-009)",
        "usage_notes": "ONLY user_listener uses sound=True. Background agents use sound=False.",
        "related_tables": '["notification_system_state"]',
    },
    {
        "entity_name": "notification_system_state",
        "description": "System state for notification management",
        "purpose": "Track notification delivery and prevent duplicates",
        "usage_notes": "Managed by notification system. Read-only for agents.",
        "related_tables": '["notification_user"]',
    },
    {
        "entity_name": "notifications",
        "description": "Legacy notification table (being phased out)",
        "purpose": "Old notification system - DO NOT USE for new code",
        "usage_notes": "Use notification_user instead. This table exists for migration only.",
        "related_tables": '["notification_user"]',
    },
    # METRICS DOMAIN
    {
        "entity_name": "metrics_subtask",
        "description": "Performance metrics for subtask execution",
        "purpose": "Track execution time and success rates for tasks",
        "usage_notes": "Used for performance analysis and optimization",
        "related_tables": '["specs_task"]',
    },
    # SYSTEM DOMAIN
    {
        "entity_name": "system_audit",
        "description": "System-wide audit trail for all database changes",
        "purpose": "Comprehensive audit log for compliance and debugging",
        "usage_notes": "Automatically populated. Immutable after creation.",
        "related_tables": "[]",
    },
    {
        "entity_name": "system_schema_metadata",
        "description": "Self-documenting database schema metadata",
        "purpose": "Store human-readable documentation for all tables and columns",
        "usage_notes": "Used by database_schema_guide skill for agent awareness. Update via skill.",
        "related_tables": "[]",
    },
]


# Legitimate view definitions (JOIN views that should stay)
LEGITIMATE_VIEWS = {
    "implementation_tasks_view": """
        CREATE VIEW implementation_tasks_view AS
        SELECT
            t.task_id,
            t.priority_number,
            t.task_group_id,
            t.priority_order,
            t.spec_id,
            s.roadmap_item_id,
            t.scope_description,
            t.assigned_files,
            t.spec_sections,
            t.status,
            t.process_id,
            t.worktree_path,
            t.branch_name,
            t.claimed_at,
            t.started_at,
            t.completed_at,
            t.created_at
        FROM specs_task t
        JOIN specs_specification s ON t.spec_id = s.id
    """,
    "spec_progress_view": """
        CREATE VIEW spec_progress_view AS
        SELECT
            s.id,
            s.spec_number,
            s.title,
            s.status,
            s.roadmap_item_id,
            s.spec_type,
            s.created_at,
            s.updated_at
        FROM specs_specification s
    """,
}


# View documentation
VIEW_DOCS = [
    {
        "entity_name": "implementation_tasks_view",
        "description": "JOIN view combining tasks with their specification metadata",
        "purpose": "Provide enriched task information including roadmap_item_id from spec",
        "usage_notes": "Use for querying tasks with spec context. Includes roadmap lineage.",
        "related_tables": '["specs_task", "specs_specification"]',
    },
    {
        "entity_name": "spec_progress_view",
        "description": "Simplified view of specification progress and status",
        "purpose": "Quick access to spec status without full content",
        "usage_notes": "Lightweight view for dashboards and status checks",
        "related_tables": '["specs_specification"]',
    },
]


def document_tables(conn):
    """Add documentation for all 20 tables.

    Returns:
        int: Number of tables documented
    """
    cursor = conn.cursor()
    documented = 0

    for doc in TABLE_DOCS:
        try:
            cursor.execute(
                """
                INSERT OR REPLACE INTO system_schema_metadata (
                    entity_type, entity_name, parent_name, description, purpose,
                    usage_notes, content_type, use_files, related_tables, foreign_keys,
                    created_at, updated_at
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            """,
                (
                    "table",
                    doc["entity_name"],
                    None,  # parent_name
                    doc["description"],
                    doc["purpose"],
                    doc["usage_notes"],
                    doc.get("content_type"),
                    0,  # use_files
                    doc.get("related_tables"),
                    None,  # foreign_keys
                ),
            )
            documented += 1
        except Exception as e:
            print(f"  ⚠️  Error documenting {doc['entity_name']}: {e}")

    conn.commit()
    return documented


def recreate_legitimate_views(conn):
    """Drop and recreate legitimate views with new table names.

    Returns:
        int: Number of views recreated
    """
    cursor = conn.cursor()
    recreated = 0

    for view_name, view_sql in LEGITIMATE_VIEWS.items():
        try:
            # Drop old view
            cursor.execute(f"DROP VIEW IF EXISTS {view_name}")

            # Create new view
            cursor.execute(view_sql)
            recreated += 1
        except Exception as e:
            print(f"  ⚠️  Error recreating {view_name}: {e}")

    conn.commit()
    return recreated


def drop_backward_compat_views(conn):
    """Drop all backward-compatibility views.

    Returns:
        int: Number of views dropped
    """
    cursor = conn.cursor()

    # List of backward-compat views to drop
    views_to_drop = [
        "roadmap_items",
        "technical_specs",
        "implementation_tasks",
        "task_group_dependencies",
        "code_reviews",
        "implementation_commits",
        "audit_trail",
        "schema_metadata",
        "roadmap_update_notifications",
        "orchestrator_tasks",
        "bugs",
        "agent_messages",
        "subtask_metrics",
    ]

    dropped = 0
    for view_name in views_to_drop:
        try:
            cursor.execute(f"DROP VIEW IF EXISTS {view_name}")
            dropped += 1
        except Exception as e:
            print(f"  ⚠️  Error dropping {view_name}: {e}")

    conn.commit()
    return dropped


def document_views(conn):
    """Add documentation for legitimate views.

    Returns:
        int: Number of views documented
    """
    cursor = conn.cursor()
    documented = 0

    for doc in VIEW_DOCS:
        try:
            cursor.execute(
                """
                INSERT OR REPLACE INTO system_schema_metadata (
                    entity_type, entity_name, parent_name, description, purpose,
                    usage_notes, content_type, use_files, related_tables, foreign_keys,
                    created_at, updated_at
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            """,
                (
                    "view",
                    doc["entity_name"],
                    None,
                    doc["description"],
                    doc["purpose"],
                    doc["usage_notes"],
                    None,
                    0,
                    doc.get("related_tables"),
                    None,
                ),
            )
            documented += 1
        except Exception as e:
            print(f"  ⚠️  Error documenting view {doc['entity_name']}: {e}")

    conn.commit()
    return documented


def migrate():
    """Run Phase 4: Documentation and Cleanup."""

    print("=" * 80)
    print(" DATABASE CONSOLIDATION - Phase 4: Documentation & Cleanup")
    print("=" * 80)
    print()
    print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    target_db = Path("data/roadmap.db")

    if not target_db.exists():
        print(f"❌ Target database not found: {target_db}")
        return False

    conn = sqlite3.connect(target_db)

    # Step 1: Document all tables
    print("📋 Documenting All Tables")
    print("-" * 80)
    documented_tables = document_tables(conn)
    print(f"  ✅ Documented {documented_tables}/20 tables")
    print()

    # Step 2: Recreate legitimate views with new table names
    print("🔄 Recreating Legitimate Views (with new table names)")
    print("-" * 80)
    recreated_views = recreate_legitimate_views(conn)
    print(f"  ✅ Recreated {recreated_views} legitimate views")
    print()

    # Step 3: Drop backward-compatibility views
    print("🗑️  Dropping Backward-Compatibility Views")
    print("-" * 80)
    dropped_views = drop_backward_compat_views(conn)
    print(f"  ✅ Dropped {dropped_views} backward-compat views")
    print()

    # Step 4: Document legitimate views
    print("📋 Documenting Legitimate Views")
    print("-" * 80)
    documented_views = document_views(conn)
    print(f"  ✅ Documented {documented_views} views")
    print()

    conn.close()

    # Summary
    print("=" * 80)
    print(" MIGRATION SUMMARY")
    print("=" * 80)
    print()
    print(f"✅ Tables documented: {documented_tables}/20")
    print(f"✅ Legitimate views recreated: {recreated_views}")
    print(f"✅ Backward-compat views dropped: {dropped_views}")
    print(f"✅ Views documented: {documented_views}")
    print()
    print(f"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # Verification
    print("=" * 80)
    print(" VERIFICATION")
    print("=" * 80)
    print()

    conn = sqlite3.connect(target_db)
    cursor = conn.cursor()

    # Check documentation coverage
    cursor.execute("SELECT COUNT(*) FROM system_schema_metadata WHERE entity_type = 'table'")
    doc_count = cursor.fetchone()[0]
    print(f"📊 Documented tables: {doc_count}/20")

    cursor.execute("SELECT COUNT(*) FROM system_schema_metadata WHERE entity_type = 'view'")
    view_doc_count = cursor.fetchone()[0]
    print(f"📊 Documented views: {view_doc_count}")

    # List remaining views
    cursor.execute("SELECT name FROM sqlite_master WHERE type = 'view' ORDER BY name")
    remaining_views = [row[0] for row in cursor.fetchall()]
    print(f"\n📋 Remaining views ({len(remaining_views)}):")
    for view in remaining_views:
        print(f"   • {view}")

    # Check if old table names still work (they shouldn't)
    print(f"\n🔍 Testing old table names (should fail):")
    for old_name in ["roadmap_items", "technical_specs", "implementation_tasks"]:
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {old_name}")
            print(f"   ⚠️  {old_name} STILL EXISTS (unexpected!)")
        except sqlite3.OperationalError:
            print(f"   ✅ {old_name} properly removed")

    # Check if new table names work
    print(f"\n✅ Testing new table names (should work):")
    for new_name in ["roadmap_priority", "specs_specification", "specs_task"]:
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {new_name}")
            count = cursor.fetchone()[0]
            print(f"   ✅ {new_name}: {count} rows")
        except sqlite3.OperationalError as e:
            print(f"   ❌ {new_name}: {e}")

    conn.close()

    print()
    print("=" * 80)
    print(" NEXT STEPS")
    print("=" * 80)
    print()
    print("1. ✅ All tables documented in system_schema_metadata")
    print("2. ✅ Legitimate views recreated with new table names")
    print("3. ✅ Backward-compat views dropped")
    print("4. ⏭️  Run tests to ensure nothing broke")
    print("5. ⏭️  Update any remaining code using old table names (should be none)")
    print()

    return True


if __name__ == "__main__":
    success = migrate()
    exit(0 if success else 1)
