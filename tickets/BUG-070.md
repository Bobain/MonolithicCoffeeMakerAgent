# BUG-070: Orchestrator spawns duplicate code_developers without worktree isolation

**Status**: üü° Partially Fixed (Bug 1 & 2 resolved, Bug 3 remains)
**Priority**: Critical
**Created**: 2025-10-20T17:15:00
**Reporter**: user_listener
**Assigned**: code_developer
**Category**: concurrency

## Description

The orchestrator spawns multiple code_developer instances for the same priority WITHOUT git worktree isolation, causing file conflicts and race conditions.

**Evidence**: 9 code_developers running simultaneously on `--priority=036`, all in the same directory:
- PIDs: 70298, 70283, 69358, 69354, 64868, 64865, 64228, 64224, 62322
- All spawned between 16:54 and 17:13
- All working on task `impl-036`
- **None have worktree_path set** (all NULL in database)

**Database proof**:
```
sqlite3 data/orchestrator.db "SELECT pid, task_id, status, spawned_at, worktree_path FROM agent_lifecycle WHERE agent_type='code_developer' AND task_id='impl-036' AND status='spawned' ORDER BY spawned_at DESC"
```

## Root Cause

**Bug 1: Safety check uses in-memory state instead of database**

File: `coffee_maker/orchestrator/continuous_work_loop.py:560-564`

```python
active_impl_count = sum(1 for key in self.current_state.get("active_tasks", {}) if key.startswith("impl_"))

if active_impl_count > 0:
    logger.debug(f"{active_impl_count} implementations already in progress")
    return
```

Problem: `current_state["active_tasks"]` is **in-memory only** and gets cleared on orchestrator restart. It doesn't reflect the actual database state.

**Bug 2: Sequential code_developer spawning doesn't use worktrees (CFR-013 VIOLATION)**

File: `coffee_maker/orchestrator/continuous_work_loop.py:604-608`

```python
result = self.agent_mgmt.execute(
    action="spawn_code_developer",
    priority_number=next_priority["number"],
    auto_approve=True,
)
```

Problem: Missing `worktree_path` parameter. All code_developers work in the same directory.

**CFR-013 MANDATORY ISOLATION RULE (Added 2025-10-20)**:
> NO TWO code_developer instances may EVER work in the same directory.
> EVERY code_developer instance MUST have its own isolated git worktree.
> Even for sequential execution (one at a time), worktrees are MANDATORY.

**Why this matters**: Even without direct file conflicts, multiple code_developers in the same directory cause:
- Test failures (one agent's changes breaking another's tests)
- Git staging area conflicts
- Race conditions in build artifacts
- Database/config file conflicts
- Process lock conflicts

**Bug 3: Orchestrator doesn't enforce singleton (CFR-000 violation)**

The orchestrator itself violates CFR-000 by not using AgentRegistry. During testing, **3 orchestrator instances** were running simultaneously:
- PID 62292 (started 4:54)
- PID 62492 (started 4:54)
- PID 81485 (started 5:17)

All 3 orchestrators were spawning code_developers independently, causing the duplicate spawning issue.

Problem: `continuous_work_loop.py` doesn't use `AgentRegistry.register(AgentType.ORCHESTRATOR)` context manager.

## Impact

- **File conflicts**: Multiple agents editing the same files simultaneously
- **Race conditions**: Git commits overwriting each other
- **Wasted resources**: 9 processes doing duplicate work
- **Database pollution**: Hundreds of duplicate spawn records
- **CFR-000 violation**: Multiple agent instances of same type working on same task

## Reproduction Steps

1. Start orchestrator: `poetry run orchestrator start`
2. Wait for it to spawn code_developer for priority 036
3. Restart orchestrator (clears in-memory state but database still shows "spawned")
4. Observe orchestrator spawns another code_developer for same priority
5. Repeat steps 3-4 several times
6. Check processes: `ps aux | grep "code-developer.*priority=036"`
7. Observe multiple processes running on same priority

## Expected Behavior

1. Safety check should query database, not in-memory state
2. Only ONE code_developer per priority at a time (unless worktrees are used)
3. If sequential execution, wait for current code_developer to finish
4. If parallel execution, use git worktrees for isolation

## Actual Behavior

- Orchestrator spawns unlimited code_developers for same priority
- All work in same directory without isolation
- Safety check fails to prevent duplicates after restart

## Definition of Done

- [x] Bug reproduced locally
- [x] Root cause identified
- [x] Fix 1: Safety check queries database instead of in-memory state **‚úÖ DONE**
- [x] Fix 2: Sequential spawning creates mandatory worktrees **‚úÖ DONE**
- [ ] Fix 3: Orchestrator enforces singleton using AgentRegistry
- [ ] Regression tests added
- [ ] All tests passing
- [x] Verified: No duplicate spawning with single orchestrator instance **‚úÖ DONE**
- [ ] Verified: Worktree isolation enforced
- [ ] PR created and reviewed

## Technical Spec

**Fix 1: Database-backed safety check**

Replace lines 560-564 in `continuous_work_loop.py`:

```python
# Query database for active implementations (not in-memory state)
result = self.agent_mgmt.execute(action="list_active_agents", include_completed=False)
active_agents = result.get("result", {}).get("active_agents", [])
active_impl_count = sum(1 for agent in active_agents if agent.get("task_type") == "implementation")

if active_impl_count > 0:
    logger.debug(f"{active_impl_count} implementations already in progress")
    return
```

**Fix 2: ALWAYS create worktrees for code_developer spawning**

**REQUIRED** (per CFR-013 Mandatory Isolation Rule):
```python
# EVERY code_developer spawn MUST create worktree
worktree_id = generate_worktree_id()  # e.g., "wt1", "wt2"
worktree_path = f"../worktree-{worktree_id}"
worktree_branch = f"roadmap-{worktree_id}"

# Create worktree
subprocess.run(["git", "worktree", "add", worktree_path, "-b", worktree_branch])

# Spawn code_developer IN worktree
result = self.agent_mgmt.execute(
    action="spawn_code_developer",
    priority_number=next_priority["number"],
    worktree_path=worktree_path,  # ‚úÖ MANDATORY
    auto_approve=True,
)
```

NO exceptions - worktrees are MANDATORY for:
- ‚úÖ Parallel execution (multiple code_developers)
- ‚úÖ Sequential execution (one code_developer at a time)
- ‚úÖ ALL code_developer spawns, period

## Implementation Status

**Fix 1: COMPLETED ‚úÖ**

File: `coffee_maker/orchestrator/continuous_work_loop.py:559-572`

Replaced in-memory safety check with database query:
```python
# Check if any work already in progress (query database, not in-memory state)
# BUG-070 fix: Must query database because in-memory state clears on restart
result = self.agent_mgmt.execute(action="list_active_agents", include_completed=False)

if result.get("error"):
    logger.error(f"Failed to check active agents: {result['error']}")
    return

active_agents = result.get("result", {}).get("active_agents", [])
active_impl_count = sum(1 for agent in active_agents if agent.get("task_type") == "implementation")

if active_impl_count > 0:
    logger.debug(f"{active_impl_count} implementations already in progress (database check)")
    return
```

**Test Results**:
- **Before fix**: 9 code_developers on priority 036 simultaneously
- **After fix**: Only 1 code_developer per priority (tested with single orchestrator)
- **Verified**: Spawned US-037, then US-036 (different priorities, no duplicates)

**Fix 2: COMPLETED ‚úÖ**

File: `coffee_maker/orchestrator/continuous_work_loop.py`

**Changes Made**:

1. **Modified sequential spawning** (lines 600-670):
   - Added CFR-013 compliance comment
   - Generate unique worktree ID via `_generate_worktree_id()`
   - Create worktree: `git worktree add ../worktree-{id} -b roadmap-{id}`
   - Pass `worktree_path` to spawn_code_developer
   - Track worktree info in active_tasks dictionary
   - Added error handling with worktree cleanup on spawn failure

2. **Added `_generate_worktree_id()` method** (lines 839-872):
   - Queries database for existing worktrees
   - Finds highest worktree number in use
   - Returns next available ID (e.g., "wt1", "wt2", "wt3")
   - Fallback to timestamp-based ID if database query fails

3. **Added `_cleanup_worktree()` method** (lines 874-915):
   - Removes worktree directory: `git worktree remove --force`
   - Deletes branch: `git branch -D roadmap-{id}`
   - Error handling and logging
   - Timeout protection (30 seconds)

4. **Added cleanup trigger** (lines 705-711):
   - Detects completed tasks in `_monitor_tasks()`
   - Automatically cleans up worktrees when code_developer finishes
   - Logs cleanup actions

**Enforcement**:
- ‚ùå IMPOSSIBLE to spawn code_developer without worktree
- ‚úÖ MANDATORY worktree creation for ALL code_developer spawns
- ‚úÖ Automatic cleanup when task completes

**Remaining Work**:
- Fix 3: Add AgentRegistry singleton enforcement for orchestrator itself
- Test worktree isolation with actual code_developer spawns
- Verify cleanup works correctly

## Notes

- This is a **CRITICAL** bug that violates CFR-000 (singleton agent enforcement)
- Related to CFR-013 (git workflow) and CFR-014 (database tracing)
- Discovered while fixing BUG-069
- **Partial fix applied**: Bug 1 resolved, Bugs 2 & 3 require additional work
