# US-023: Settings Management from project-manager UI

**Status**: 📝 Planned
**Priority**: Medium
**Estimate**: 6-8 hours

## User Story
As a user,
I want to be able to change settings (provider, model, etc.) from the project-manager UI,
So that I can configure the system without manually editing .env files or code.

## Problem
Currently, users must:
- Manually edit `.env` files to change API keys
- Modify code to change LLM providers or models
- Restart services after configuration changes
- No visibility into current settings
- No validation of configuration values
- Risk of syntax errors in manual edits

## Proposed Solution
Add a `/settings` command to project-manager CLI with interactive configuration UI.

### Settings to Manage
```yaml
LLM Configuration:
  - Provider: anthropic | openai | gemini
  - Model: claude-sonnet-4 | gpt-4 | gemini-pro
  - Temperature: 0.0 - 2.0
  - Max tokens: 1000 - 100000

Daemon Configuration:
  - Auto-approve: true | false
  - Create PRs: true | false
  - Sleep interval: 10 - 300 seconds
  - Max crashes: 1 - 10
  - Compact interval: 5 - 50 iterations

Project Manager Configuration:
  - Enable streaming: true | false
  - Default editor: vim | nano | vscode | emacs
  - Notification preferences: all | critical | none

GitHub Configuration:
  - Default branch: main | master | custom
  - PR auto-merge: true | false
  - Required reviewers: number
```

## UI Design

### Main Settings Menu
```
╔════════════════════════════════════════════════════════════╗
║                    Settings Manager                        ║
╠════════════════════════════════════════════════════════════╣
║                                                            ║
║  [1] LLM Configuration                                     ║
║      Provider: anthropic (Claude)                          ║
║      Model: claude-sonnet-4                                ║
║      Status: ✅ API Key configured                         ║
║                                                            ║
║  [2] Daemon Configuration                                  ║
║      Auto-approve: Yes                                     ║
║      Create PRs: Yes                                       ║
║      Status: 🟢 Running (PID: 12345)                       ║
║                                                            ║
║  [3] Project Manager Configuration                         ║
║      Streaming: Enabled                                    ║
║      Editor: vim                                           ║
║                                                            ║
║  [4] GitHub Configuration                                  ║
║      Default branch: main                                  ║
║      Status: ✅ Token configured                           ║
║                                                            ║
║  [5] View All Settings (as JSON)                           ║
║  [6] Reset to Defaults                                     ║
║  [7] Export Configuration                                  ║
║                                                            ║
║  [0] Back to Main Menu                                     ║
║                                                            ║
╚════════════════════════════════════════════════════════════╝

Select option (0-7):
```

### LLM Configuration Submenu
```
╔════════════════════════════════════════════════════════════╗
║              LLM Configuration                             ║
╠════════════════════════════════════════════════════════════╣
║                                                            ║
║  Current Configuration:                                    ║
║  • Provider: anthropic                                     ║
║  • Model: claude-sonnet-4                                  ║
║  • Temperature: 0.0                                        ║
║  • Max tokens: 10000                                       ║
║  • API Key: ✅ Configured (ends in ...xyz)                 ║
║                                                            ║
║  [1] Change Provider                                       ║
║  [2] Change Model                                          ║
║  [3] Change Temperature                                    ║
║  [4] Change Max Tokens                                     ║
║  [5] Configure API Key                                     ║
║  [6] Test Connection                                       ║
║                                                            ║
║  [0] Back                                                  ║
║                                                            ║
╚════════════════════════════════════════════════════════════╝

Select option (0-6):
```

### Provider Selection
```
╔════════════════════════════════════════════════════════════╗
║              Select LLM Provider                           ║
╠════════════════════════════════════════════════════════════╣
║                                                            ║
║  [1] Anthropic (Claude)                                    ║
║      ✅ Recommended                                        ║
║      ✅ Best for code generation                           ║
║      ✅ 200k context window                                ║
║      💰 Costs: ~$3/$15 per 1M tokens                       ║
║      Status: ✅ API Key configured                         ║
║                                                            ║
║  [2] OpenAI (GPT-4)                                        ║
║      ✅ Good for code generation                           ║
║      ⚠️  128k context window                               ║
║      💰 Costs: ~$2.50/$10 per 1M tokens                    ║
║      Status: ❌ API Key not configured                     ║
║                                                            ║
║  [3] Google (Gemini)                                       ║
║      ✅ Large context window (2M tokens)                   ║
║      ⚠️  Beta quality for code                             ║
║      💰 Free tier available                                ║
║      Status: ✅ API Key configured                         ║
║                                                            ║
║  [0] Cancel                                                ║
║                                                            ║
╚════════════════════════════════════════════════════════════╝

Select provider (0-3):
```

## Technical Implementation

### Architecture
```python
coffee_maker/cli/
├── settings_manager.py          # New: Settings management
├── settings_display.py          # New: Rich UI for settings
└── settings_validator.py        # New: Validation logic

coffee_maker/
├── config.py                    # Enhanced: Add settings methods
└── settings.json                # New: User settings storage
```

### Settings Storage
Location: `~/.coffee_maker/settings.json`
```json
{
  "llm": {
    "provider": "anthropic",
    "model": "claude-sonnet-4",
    "temperature": 0.0,
    "max_tokens": 10000,
    "api_keys": {
      "anthropic": "sk-ant-...",
      "openai": "sk-...",
      "gemini": "AIza..."
    }
  },
  "daemon": {
    "auto_approve": true,
    "create_prs": true,
    "sleep_interval": 30,
    "max_crashes": 3,
    "compact_interval": 10
  },
  "project_manager": {
    "enable_streaming": true,
    "default_editor": "vim",
    "notifications": "all"
  },
  "github": {
    "default_branch": "main",
    "auto_merge": false,
    "required_reviewers": 1
  },
  "version": "1.0",
  "last_updated": "2025-10-11T15:30:00Z"
}
```

### Command Examples
```bash
# Open settings UI
project-manager settings

# View current settings
project-manager settings --view

# Change specific setting
project-manager settings set llm.provider anthropic
project-manager settings set daemon.auto_approve false

# Get specific setting
project-manager settings get llm.provider

# Test LLM connection
project-manager settings test llm

# Reset to defaults
project-manager settings reset

# Export settings
project-manager settings export > my-settings.json

# Import settings
project-manager settings import my-settings.json
```

## Acceptance Criteria

### Must Have
- [ ] Interactive settings UI accessible via `/settings` command
- [ ] View current settings for all categories
- [ ] Change LLM provider (anthropic, openai, gemini)
- [ ] Change LLM model
- [ ] Configure API keys securely (masked display)
- [ ] Change daemon settings (auto-approve, create PRs, intervals)
- [ ] Validate all input (range checks, format validation)
- [ ] Test LLM connection before saving
- [ ] Settings persist to `~/.coffee_maker/settings.json`
- [ ] Apply settings immediately (no restart required for most settings)
- [ ] Display current status indicators (API key configured, daemon running, etc.)

### Should Have
- [ ] Reset to defaults option
- [ ] Export/import settings to JSON
- [ ] Show cost estimates per provider
- [ ] Highlight recommended settings
- [ ] Validation error messages with suggestions
- [ ] Confirm before dangerous operations (reset, delete)
- [ ] Display settings history/changelog

### Nice to Have
- [ ] Settings search/filter
- [ ] Settings templates (development, production, minimal cost)
- [ ] Auto-detect optimal settings
- [ ] Settings migration wizard for upgrades
- [ ] Settings diff when importing
- [ ] Backup settings before changes

## Security Considerations

1. **API Key Storage**
   - Store in `~/.coffee_maker/settings.json` with 0600 permissions
   - Mask display: `sk-ant-...xyz` (show only last 3 chars)
   - Never log API keys
   - Validate format before saving

2. **Input Validation**
   - Whitelist allowed values for enums
   - Range checks for numeric values
   - Format validation for strings
   - Prevent injection attacks

3. **File Permissions**
   - Settings file: 0600 (user read/write only)
   - Config directory: 0700 (user access only)

## Implementation Plan

### Phase 1: Core Settings Infrastructure (2-3 hours)
1. Create `SettingsManager` class
2. Implement settings persistence (JSON)
3. Add validation framework
4. Update `ConfigManager` to read from settings.json

### Phase 2: Interactive UI (2-3 hours)
1. Create Rich-based settings display
2. Implement navigation menus
3. Add input prompts with validation
4. Implement status indicators

### Phase 3: Integration (1-2 hours)
1. Add `/settings` command to chat interface
2. Update daemon to read settings
3. Update AI service to read settings
4. Add settings migration

### Phase 4: Testing & Polish (1 hour)
1. Test all settings changes
2. Test validation
3. Test persistence
4. Add documentation

## Benefits

1. **User Experience**
   - No manual file editing
   - Visual feedback and validation
   - Easy provider switching
   - Real-time status indicators

2. **Reliability**
   - Input validation prevents errors
   - Settings persistence
   - Safe defaults
   - Rollback capability

3. **Flexibility**
   - Easy experimentation with providers
   - Quick configuration changes
   - Settings templates
   - Export/import for teams

## Related User Stories
- US-021: Code Refactoring (ConfigManager enhancement)
- PRIORITY 2.9.5: Transparent Assistant Integration (provider selection)
- Future: Settings sync across team members

## Technical Notes
- Use Rich library for interactive menus
- Use prompt_toolkit for input with validation
- Store encrypted API keys (optional enhancement)
- Add settings schema versioning for migrations
- Consider environment variable overrides

## Example Usage Session
```
$ project-manager settings

> Select: [1] LLM Configuration
> Select: [1] Change Provider
> Current: anthropic
> Select: [2] OpenAI (GPT-4)
> Enter API key: sk-...
> Testing connection... ✅ Success!
> Save changes? [Y/n]: y
> ✅ Settings saved. Restart daemon to apply.
```
